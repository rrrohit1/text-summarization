{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, TrainingArguments, DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/accrete-ai/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('/Users/rohitrawat/job-prep/Assignments/accrete-ai/text-summarization/data/processed/news_summary_cleaned_train.csv')\n",
    "\n",
    "# Convert the DataFrame to a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Load the tokenizer and model\n",
    "model_name = \"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5ea7897dd24654b2e470e9c0fc1c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocess the data: tokenizing\n",
    "def preprocess_function(examples):\n",
    "    inputs = tokenizer(examples['text'], max_length=512, truncation=True, padding=\"max_length\")\n",
    "    targets = tokenizer(examples['summary'], max_length=150, truncation=True, padding=\"max_length\")\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "# Apply the preprocessing function to the dataset\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/accrete-ai/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./flan_t5_small_finetuned\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    # predict_with_generate=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    ")\n",
    "\n",
    "# Data collator for padding and dynamic length inputs\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset,  # Replace with a separate validation set if available\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ec0d8dd2ce4745a0022e2e1cba0b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 26.4186, 'grad_norm': 92.001708984375, 'learning_rate': 1.8787878787878792e-05, 'epoch': 0.18}\n",
      "{'loss': 24.1238, 'grad_norm': 71.7027359008789, 'learning_rate': 1.7575757575757576e-05, 'epoch': 0.36}\n",
      "{'loss': 22.3889, 'grad_norm': 78.78324127197266, 'learning_rate': 1.6363636363636366e-05, 'epoch': 0.55}\n",
      "{'loss': 20.9566, 'grad_norm': 85.72879791259766, 'learning_rate': 1.5151515151515153e-05, 'epoch': 0.73}\n",
      "{'loss': 18.3504, 'grad_norm': 82.81512451171875, 'learning_rate': 1.3939393939393942e-05, 'epoch': 0.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d315dbb0dddb43579456e94c32b1f049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 16.157461166381836, 'eval_runtime': 31.7463, 'eval_samples_per_second': 6.898, 'eval_steps_per_second': 1.732, 'epoch': 1.0}\n",
      "{'loss': 17.6504, 'grad_norm': 69.0825424194336, 'learning_rate': 1.2727272727272728e-05, 'epoch': 1.09}\n",
      "{'loss': 15.3431, 'grad_norm': 58.20634460449219, 'learning_rate': 1.1515151515151517e-05, 'epoch': 1.27}\n",
      "{'loss': 14.2781, 'grad_norm': 63.513179779052734, 'learning_rate': 1.0303030303030304e-05, 'epoch': 1.45}\n",
      "{'loss': 13.3977, 'grad_norm': 44.723480224609375, 'learning_rate': 9.090909090909091e-06, 'epoch': 1.64}\n",
      "{'loss': 11.4901, 'grad_norm': 53.80904006958008, 'learning_rate': 7.87878787878788e-06, 'epoch': 1.82}\n",
      "{'loss': 11.1259, 'grad_norm': 56.10178756713867, 'learning_rate': 6.666666666666667e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601685d0f1944d9282ca2d2b87e17796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.617762565612793, 'eval_runtime': 195.5173, 'eval_samples_per_second': 1.12, 'eval_steps_per_second': 0.281, 'epoch': 2.0}\n",
      "{'loss': 10.3235, 'grad_norm': 48.001861572265625, 'learning_rate': 5.4545454545454545e-06, 'epoch': 2.18}\n",
      "{'loss': 10.0516, 'grad_norm': 47.112327575683594, 'learning_rate': 4.242424242424243e-06, 'epoch': 2.36}\n",
      "{'loss': 9.5545, 'grad_norm': 28.907733917236328, 'learning_rate': 3.0303030303030305e-06, 'epoch': 2.55}\n",
      "{'loss': 9.4127, 'grad_norm': 32.1888313293457, 'learning_rate': 1.8181818181818183e-06, 'epoch': 2.73}\n",
      "{'loss': 9.5473, 'grad_norm': 34.9722785949707, 'learning_rate': 6.060606060606061e-07, 'epoch': 2.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782801d110c24c9791eb356956492256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.145495414733887, 'eval_runtime': 59.2965, 'eval_samples_per_second': 3.693, 'eval_steps_per_second': 0.928, 'epoch': 3.0}\n",
      "{'train_runtime': 2351.3793, 'train_samples_per_second': 0.279, 'train_steps_per_second': 0.07, 'train_loss': 15.110159556070963, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=165, training_loss=15.110159556070963, metrics={'train_runtime': 2351.3793, 'train_samples_per_second': 0.279, 'train_steps_per_second': 0.07, 'total_flos': 122130061590528.0, 'train_loss': 15.110159556070963, 'epoch': 3.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./flan_t5_small_finetuned/tokenizer_config.json',\n",
       " './flan_t5_small_finetuned/special_tokens_map.json',\n",
       " './flan_t5_small_finetuned/tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Save the model and tokenizer\n",
    "trainer.save_model(\"./flan_t5_small_finetuned\")\n",
    "tokenizer.save_pretrained(\"./flan_t5_small_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3381d8d8e864436a89e11cb9ecc779f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(8438) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "python(8439) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "python(8442) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "import os\n",
    "\n",
    "# os.environ['HUGGINGFACE_HUB_TOKEN'] = ''\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa879d41c364ab4821c2d60abd91ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0ab95d8e204bd18b3e823ba765b605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47a6b73227740218c69d509d075f9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/rrrohit/flan_t5_small_finetuned/commit/c6e6f24ca9668272ab179f75a9f6beca7673d13b', commit_message='End of training', commit_description='', oid='c6e6f24ca9668272ab179f75a9f6beca7673d13b', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(model_name=\"flan_t5_small_finetuned_news\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "accrete-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
